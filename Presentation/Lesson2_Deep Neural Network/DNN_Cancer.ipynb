{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Breast Cancer Diagnosis ----------\n",
      "Shape of X :  (569, 30)\n",
      "Shape of Y :  (569, 2)\n",
      "---------------------------------------------\n",
      "Number of x_train :  300\n",
      "Number of y_train :  300\n",
      "Number of x_test :  268\n",
      "Number of y_test :  268\n",
      "---------------------------------------------\n",
      "INFO:tensorflow:Restoring parameters from ./cancer_model\\dnn.ckpt-10001\n",
      "Step : 10002, Cost : 0.068344\n",
      "Step : 11002, Cost : 0.086037\n",
      "Step : 12002, Cost : 0.072077\n",
      "Step : 13002, Cost : 0.072970\n",
      "Step : 14002, Cost : 0.084565\n",
      "Step : 15002, Cost : 0.081456\n",
      "Step : 16002, Cost : 0.069971\n",
      "Step : 17002, Cost : 0.085289\n",
      "Step : 18002, Cost : 0.076397\n",
      "Step : 19002, Cost : 0.108305\n",
      "Step : 20002, Cost : 0.078337\n",
      "---------------------------------------------\n",
      "정확도 : 96.27% \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def normalize(data):\n",
    "    return (data - np.min(data))/(np.max(data) - np.min(data))\n",
    "\n",
    "def add_div():\n",
    "    print(\"-\"*45)\n",
    "    \n",
    "# Load csv and preprocess dataset.\n",
    "\n",
    "dataset = np.loadtxt(\"./wisc_bc_data.csv\",delimiter=\",\",dtype=str)\n",
    "\n",
    "x_data = dataset[1:,2:].astype(np.float32) # Extract and Cast Features\n",
    "x_data = normalize(x_data) # normalize dataset\n",
    "\n",
    "y_data = dataset[1:,1] # Extract Diagnosis result\n",
    "\n",
    "y_new_data = []\n",
    "for i in range(np.shape(y_data)[0]): # Cast 'Maligant'/'Benign' as one-hot encoded float32 vector\n",
    "    if y_data[i] == 'M': # 악성\n",
    "        y_new_data.append([1. ,0.])\n",
    "    else:\n",
    "        y_new_data.append([0. ,1.])\n",
    "y_data = y_new_data\n",
    "\n",
    "print(\"-\"*10,\"Breast Cancer Diagnosis\",\"-\"*10)\n",
    "\n",
    "print(\"Shape of X : \", np.shape(x_data)) \n",
    "print(\"Shape of Y : \", np.shape(y_data))\n",
    "\n",
    "add_div()\n",
    "\n",
    "# Divide train/test set\n",
    "\n",
    "\n",
    "x_train = x_data[0:300,:] \n",
    "y_train = y_data[0:300]\n",
    "print(\"Number of x_train : \", np.shape(x_train)[0]) \n",
    "print(\"Number of y_train : \", np.shape(y_train)[0])\n",
    "\n",
    "x_test = x_data[301:,:] \n",
    "y_test = y_data[301:]\n",
    "print(\"Number of x_test : \", np.shape(x_test)[0]) \n",
    "print(\"Number of y_test : \", np.shape(y_test)[0])\n",
    "add_div()\n",
    "\n",
    "# Design neural network\n",
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0,trainable=False,name='global_step')\n",
    "X = tf.placeholder(tf.float32,[None,30])\n",
    "Y = tf.placeholder(tf.float32,[None,2])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.get_variable(\"W1\",shape=[30,20],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1 = tf.Variable(tf.random_normal([20],stddev=0.01),name=\"b1\")\n",
    "    L1 = tf.nn.relu(tf.add(tf.matmul(X,W1),b1))\n",
    "    L1 = tf.nn.dropout(L1,keep_prob)\n",
    "    \n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.get_variable(\"W2\",shape=[20,20],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2 = tf.Variable(tf.random_normal([20],stddev=0.01),name=\"b2\")\n",
    "    L2 = tf.nn.relu(tf.add(tf.matmul(L1,W2),b2))\n",
    "    L2 = tf.nn.dropout(L2,keep_prob)\n",
    "    \n",
    "with tf.name_scope('layer3'):\n",
    "    W3 = tf.get_variable(\"W3\",shape=[20,20],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b3 = tf.Variable(tf.random_normal([20],stddev=0.01),name=\"b3\")\n",
    "    L3 = tf.nn.relu(tf.add(tf.matmul(L2,W3),b3))\n",
    "    L3 = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W4 = tf.get_variable(\"W4\",shape=[20,2],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b4 = tf.Variable(tf.random_normal([2],stddev=0.01),name=\"b4\")\n",
    "    model = tf.nn.relu(tf.add(tf.matmul(L3,W4),b4))\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model,labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(0.001).minimize(cost,global_step = global_step)\n",
    "    tf.summary.scalar('cost',cost)\n",
    "    \n",
    "\n",
    "# Training neural network\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "ckpt = tf.train.get_checkpoint_state('./cancer_model')\n",
    "\n",
    "force_train = False\n",
    "\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path) and not force_train:\n",
    "    saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./cancer_logs',sess.graph)\n",
    "    \n",
    "for step in range(10001):\n",
    "    sess.run(optimizer,feed_dict={X:x_train,Y:y_train,keep_prob:0.7})\n",
    "    if step%1000 == 0:\n",
    "        print(\"Step : {:04d}, Cost : {:f}\".format(sess.run(global_step),\n",
    "                                                  sess.run(cost,feed_dict={X:x_train,Y:y_train,keep_prob:0.7})))\n",
    "    summary = sess.run(merged,feed_dict={X:x_train,Y:y_train,keep_prob:0.7})\n",
    "    writer.add_summary(summary,global_step=sess.run(global_step))\n",
    "    \n",
    "saver.save(sess,'./cancer_model/dnn.ckpt',global_step=global_step)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "add_div()\n",
    "\n",
    "print(\"정확도 : {:.2f}% \".format(100*(sess.run(accuracy,feed_dict={X:x_test,Y:y_test,keep_prob:1}))))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
